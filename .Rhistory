]
LocationNormalized.counts
aggregate(trainsal$SalaryNormalized, by = trainsal[c('LocationNormalized')], length)
trainsal <- read.csv('train.csv')
aggregate(trainsal$SalaryNormalized, by = trainsal[c('LocationNormalized')], length)
location <- aggregate(trainsal$SalaryNormalized, by = trainsal[c('LocationNormalized')], length)
location[order(x)]
sort(location)
location(order(LocationNormalized))
location[order(LocationNormalized)]
location[order(LocationNormalized),]
location[order(location$LocationNormalized),]
location[order(location$x),]
location_ordered <- location[order(location$x),]
View(location_ordered)
head(location_ordered, 610L)
head(location_ordered, -610L)
tail(location_ordered, -610L)
trainsal <- read.csv('train.csv')
location <- aggregate(trainsal, by = trainsal[c('LocationNormalized')], length)
View(location)
trainsal <- read.csv('train.csv')
location <- aggregate(trainsal$SalaryNormalized, by = trainsal[c('LocationNormalized')], length)
location_ordered <- location[order(location$x),]
location_order <- tail(location_ordered, -610L)
View(location_order)
trainsal_full <- read.csv('train.csv')
View(trainsal_full)
trainsal_exp <- merge(location_order, trainsal_full)
View(trainsal_exp)
category <- aggregate(trainsal_exp$SalaryNormalized, by =trainsal_exp[c('Category')], length)
View(category)
grepl("Senior|Snr", trainsal_exp$words)
trainsal_exp[, "Management Title"] <- grepl("Senior|Snr", trainsal_exp$words)
View(trainsal_exp)
trainsal_exp[, "Management Title"] <- grepl("Senior|Snr", trainsal_exp$Title)
View(trainsal_exp)
trainsal_exp[, "Management Title"] <- grepl("Senior|Snr|Manager|Supervisor|Deputy", trainsal_exp$Title)
View(trainsal_exp)
trainsal <- trainsal_exp
split_data <- function(dataframe, seed=NULL) {
if (!is.null(seed)) set.seed(seed)
index <- 1:nrow(dataframe)
trainindex <- sample(index, trunc(length(index)/2))
trainset <- dataframe[trainindex, ]
testset <- dataframe[-trainindex, ]
list(trainset=trainset,testset=testset)
}
split_it <- split_data(trainsal, seed=5000)
lapply(split_it,grow)
lapply(split_it,nrow)
trainsal <- split_it$trainset
testsal <- split_it$testset
view(trainsal)
View(trainsal)
head(trainsal)
model1 <- lm(SalaryNormalized ~ Category + LocationNormalized, data=trainsal)
names(trainsal)[14]<-"MgmtTitle"
model2 <- lm(SalaryNormalized ~ Category + LocationNormalized + MgmtTitle, data=trainsal)
model3 <- lm(SalaryNormalized ~ Category + MgmtTitle, data=trainsal)
mae <- function(x,y)
{
sum( abs(x-y) ) /length(x)
}
test.model1 <- predict(model1, testsal)
testsal[!testsal$LocationNormalized == "Bicester|Pontefract|Sevenoaks", ]
test.model1 <- predict(model1, testsal)
View(testsal)
testsal1 <- testsal[!testsal$LocationNormalized == "Bicester|Pontefract|Sevenoaks", ]
test.model1 <- predict(model1, testsal1)
testsal1 <- testsal[testsal$LocationNormalized != "Bicester|Pontefract|Sevenoaks", ]
test.model1 <- predict(model1, testsal1)
testsal1 <- testsal[testsal$LocationNormalized != "Bicester", ]
test.model1 <- predict(model1, testsal1)
testsal1 <- testsal[testsal$LocationNormalized != ("Bicester", "Pontefract", "Sevenoaks") ,  ]
testsal1 <- testsal[(testsal$LocationNormalized != "Pontefract") & (testsal$LocationNormalized != "Sevenoaks") ,  ]
test.model1 <- predict(model1, testsal1)
testsal1 <- testsal[(testsal$LocationNormalized != "Pontefract") & (testsal$LocationNormalized != "Sevenoaks") & (testsal$LocationNormalized != "Bicester") ,  ]
test.model1 <- predict(model1, testsal1)
test.model2 <- predict(model2, testsal1)
testsal[, "MgmtTitle"] <- grepl("Senior|Snr|Manager|Supervisor|Deputy", testsal$Title)
testsal1[, "MgmtTitle"] <- grepl("Senior|Snr|Manager|Supervisor|Deputy", testsal1$Title)
test.model2 <- predict(model2, testsal1)
test.model3 <- predict(model3, testsal1)
mae(test.model1, testsal1$NormalizedSalary)
mae(test.model2, testsal1$NormalizedSalary)
summary(model1)
summary(model2)
summary(model3)
mae <- function(x,y)
{
mean ( abs(x-y) )
}
mae(test.model1, testsal1$NormalizedSalary)
View(testsal1)
model1 <- lm(SalaryNormalized ~ Category + LocationNormalized, data=trainsal)
test.model1 <- predict(model1, testsal1)
mae(test.model1, testsal1$NormalizedSalary)
trainsal <- read.csv('train.csv')
location <- aggregate(trainsal$SalaryNormalized, by = trainsal[c('LocationNormalized')], length)
location_ordered <- location[order(location$x),]
tail(location_ordered, -610L)
location_ordered <- tail(location_ordered, -610L)
trainsal_full <- read.csv('train.csv')
trainsal <- merge(location_order, trainsal_full)
View(trainsal)
trainsal[, "MagmtTitle"] <- grepl("Senior|Snr|Manager|Supervisor|Deputy", trainsal$Title)
View(trainsal)
model.trainsal <- trainsal [,c("LocationNormalized", "ID", "Title", "ContractType", "ContractTime", "Category", "SalaryNormalized", "MgmtTitle")]
model.trainsal <- trainsal [, c("LocationNormalized", "Id", "Title", "ContractType", "ContractTime", "Category", "SalaryNormalized", "MgmtTitle")]
model.trainsal <- trainsal[, c("LocationNormalized", "Id", "Title", "ContractType", "ContractTime", "Category", "SalaryNormalized", "MgmtTitle")]
model.trainsal <- trainsal[c("LocationNormalized", "Id", "Title", "ContractType", "ContractTime", "Category", "SalaryNormalized", "MgmtTitle"),]
View(model.trainsal)
model.trainsal <- trainsal[, c("LocationNormalized", "Id", "Title", "ContractType", "ContractTime", "Category", "SalaryNormalized", "MgmtTitle"),]
model.trainsal <- trainsal[, c("LocationNormalized", "Id", "Title", "ContractType", "ContractTime", "Category", "SalaryNormalized", "MgmtTitle")]
model.trainsal <- trainsal[c-(-2, -5, -6, -9, -11, -13)]
model.trainsal <- trainsal[, c-(-2, -5, -6, -9, -11, -13)]
model.trainsal <- trainsal[, c("LocationNormalized", "Id", "Title", "ContractType", "ContractTime", "Category", "SalaryNormalized", "MgmtTitle")]
model.trainsal <- trainsal[c("-2", "-5", "-6", "-9", "-11", "-13")]
model.trainsal <- trainsal[c(-2, -5, -6, -9, -11, -13)]
View(model.trainsal)
split_data <- function(dataframe, seed=NULL) {
if (!is.null(seed)) set.seed(seed)
index <- 1:nrow(dataframe)
trainindex <- sample(index, trunc(length(index)/2))
trainset <- dataframe[trainindex, ]
testset <- dataframe[-trainindex, ]
list(trainset=trainset,testset=testset)
}
split_it <- split_data(trainsal, seed=5000)
trainsal <- split_it$trainset
testsal <- split_it$testset
View(trainsal)
split_it <- split_data(model.trainsal, seed=5000)
trainsal <-spli_it$trainset
trainsal <-split_it$trainset
testsal <- split_it$testset
View(trainsal)
View(testsal)
model1 <- lm(SalaryNormalized ~ LocationNormalized, data=trainsal)
model1 <- lm(SalaryNormalized ~ LocationNormalized + Category, data=trainsal)
model1 <- lm(SalaryNormalized ~ LocationNormalized, data=trainsal)
model2 <- lm(SalaryNormalized ~ LocationNormalized + Category, data=trainsal)
model3 <- lm(SalaryNormalized ~ Category + ContractType, data=trainsal)
model3 <- lm(SalaryNormalized ~ Category + ContractType + ContractTime, data=trainsal)
model3 <- lm(SalaryNormalized ~ Category + ContractType, data=trainsal)
model4 <- lm(SalaryNormalized ~ Category + ContractType + ContractTime, data=trainsal)
model5 <- lm(SalaryNormalized ~ Category + MgmtTitle, data=trainsal)
model5 <- lm(SalaryNormalized ~ Category + MagmtTitle, data=trainsal)
test.model1 <- predict(model1, testsal)
testsal1 <- testsal[(testsal$LocationNormalized != "Pontefract") & (testsal$LocationNormalized != "Sevenoaks") & (testsal$LocationNormalized != "Bicester") ,  ]
test.model1 <- predict(model1, testsal1)
test.model2 <- predict(model2, testsal1)
test.model3 <- predict(model3, testsal1)
test.model4 <- predict(model4, testsal1)
test.model5 <- predict(model5, testsal1)
mae <- function(x,y)
{
mean( abs(x-y) ) /length(x)
}
mae(test.model1, testsal1$SalaryNormalized)
mae(test.model2, testsal1$SalaryNormalized)
mae(test.model3, testsal1$SalaryNormalized)
mae(test.model4, testsal1$SalaryNormalized)
mae(test.model5, testsal1$SalaryNormalized)
summary(model1)
summary(model2)
summary(model3)
summary(model4)
summary(model5)
model6 <- lm(SalaryNormalized ~ LocationNormalized + Category + MagmtTitle + ContractType + ContractTime, data=trainsal)
model7 <- lm(SalaryNormalized ~ LocationNormalized + Category + ContractType + ContractTime, data=trainsal)
model8 <- lm(SalaryNormalized ~ Category + ContractType + ContractTime + MagmtTitle, data=trainsal)
model9 <- lm(SalaryNormalized ~ LocationNormalized + Category + MagmtTitle, data=trainsal)
test.model6 <- predict(model6, testsal)
test.model6 <- predict(model6, testsal1)
test.model7 <- predict(model7, testsal1)
test.model8 <- predict(model8, testsal1)
test.model10 <- predict(model9, testsal1)
mae(test.model6, testsal1$SalaryNormalized)
mae(test.model7, testsal1$SalaryNormalized)
mae(test.model8, testsal1$SalaryNormalized)
mae(test.model9, testsal1$SalaryNormalized)
mae(test.model10, testsal1$SalaryNormalized)
summary(model6)
summary(model7)
summary(model8)
summary(model9)
model10 <- lm(SalaryNormalized ~ LocationNormalized + Category + MagmtTitle + ContractType, data=trainsal)
test.model10 <- predict(model10, testsal1)
mae(test.model10, testsal1$SalaryNormalized)
model10 <- lm(SalaryNormalized ~ LocationNormalized + Category + MagmtTitle + ContractTime, data=trainsal)
test.model10 <- predict(model10, testsal1)
mae(test.model10, testsal1$SalaryNormalized)
model10 <- lm(SalaryNormalized ~ LocationNormalized + MagmtTitle, data=trainsal)
mae(test.model10, testsal1$SalaryNormalized)
test.model10 <- predict(model10, testsal1)
mae(test.model10, testsal1$SalaryNormalized)
install.packages('DAAG')
library('DAAG')
cv.lm(df=testsal, form.lm=formula(SalaryNormalized ~ LocationNormalized + Category + MagmtTitle + ContractType + ContractTime), m=2)
cv.lm(df=testsal1, form.lm=formula(SalaryNormalized ~ LocationNormalized + Category + MagmtTitle + ContractType + ContractTime), m=2)
q()
mae <- function(one, other) {
return(mean(abs(one - other)))
}
mae(5, 2)
alltrain <- read.csv("train.csv")
alltrain <- read.csv("train-1.csv")
set.seed(42)
alltrain$fold <- sample(1:10, nrow(alltrain), replace = TRUE)
train <- subset(alltrain, fold != 3)
test <- subset(alltrain, fold == 3)
#what is the dumbest model we could do? Let'spredict every salary is
mae(0, train$SalaryNormalized)
mae(0, test$SalaryNormalized)
hist(train$SalaryNormalized)
model <- lm(SalaryNormalized ~ 1, data=training)
#second dumbest model is to predict every salary is the mean, which is what the 1 above stands for
mae(fitted(model), train$SalaryNormalized)
mae(predict(model,test), test$SalaryNormalized)
error_from_fold <- function(n) {
model <- lm(Salary$Normalized -1, data=subset(alltrain, fold != n))
test <- subset(alltrain, fold == n)
error <- mae(predict(model,test), test$SalaryNormalized)
return(error)
}
error_from_fold(3)
error_from_fold <- function(n) {
model <- lm(SalaryNormalized ~ 1, data=subset(alltrain, fold != n))
test <- subset(alltrain, fold == n)
error <- mae(predict(model,test), test$SalaryNormalized)
return(error)
}
error_from_fold(3)
sapply(1:10, error_from_fold)
#to work with actual test data
model <- lm(SalaryNormalized ~ ContractType, data=train)
library(glmnet)
model <- cv.glmnet(model.matrix(train$ContractType), matrix(train$SalaryNormalized))
model <- cv.glmnet(~model.matrix(train$ContractType), matrix(train$SalaryNormalized))
model <- cv.glmnet(model.matrix(~train$ContractType), matrix(train$SalaryNormalized))
as.vector(predict(model, model.matrix(~test$ContractType), s="lambda.min"))
mae(as.vector(predict(model, model.matrix(~test$ContractType), s="lambda.min")), test$SalaryNormalized)
hist(train$SalaryNormalized)
hist(log(train$SalaryNormalized))
model <- lm(log(SalaryNormalized ~ ContractType, data=train))
install.packages("knitr")
library(knitr)
data(iris)
iris$sep <- factor(ifelse(iris$Sepal.Length > 6, "big", "small"))
iris$pet <- factor(ifelse(iris$Petal.Length > 4, "long", "short"))
(counts <- with(iris, table(sep, pet)))
model <- glm(pet ~ sep, data=iris, family=binomial)
coef(model)
(logodds < predict(model)[49:52])
logodds < predict(model)[49:52]
(logodds <- predict(model)[49:52])
(probs <- predict(model, type="response")[49:52])
exp(logodds)/(1+ exp(logodds))
prob.talbe(counts,1)
prob.table(counts,1)
prop.table(counts,1)
exp(logodds)
probs / (1- probs)
coef(model)
library('ROCR')
pred <- prediction(test.predict, test$good)
beer <- read.csv('http://www-958.ibm.com/software/analytics/manyeyes/datasets/af-er-beer-dataset/versions/1.txt', header=TRUE, sep='\t')
head(beer)
beer$good <- (beer$WR > 4.3)
beer$Ale <- grepl('Ale', beer$Type)
beer$IPA <- grepl('IPA', beer$Type)
beer$Stout <- grepl('Stout', beer$Type)
train.idx <- sample(1:nrow(beer), .7*nrow(beer))
training <- beer[train.idx,]
test <- beer[-train.idx,]
model <- glm(good ~ Ale + Stout + IPA , data=training, family='binomial')
test.predict <- predict(model, test, type="response")
library('ROCR')
pred <- prediction(test.predict, test$good)
plot(pred)
beer <- read.csv('http://www-958.ibm.com/software/analytics/manyeyes/datasets/af-er-beer-dataset/versions/1.txt', header=TRUE, sep='\t')
head(beer)
beer$good <- (beer$WR > 4.3)
beer$Ale <- grepl('Ale', beer$Type)
beer$IPA <- grepl('IPA', beer$Type)
beer$Stout <- grepl('Stout', beer$Type)
train.idx <- sample(1:nrow(beer), .7*nrow(beer))
training <- beer[train.idx,]
test <- beer[-train.idx,]
model <- glm(good ~ Ale + Stout + IPA , data=training, family='binomial')
test.predict <- predict(model, test, type="response")
library('ROCR')
pred <- prediction(test.predict, test$good)
perf <- performance(pred, measure='acc')
plot(pef)
plot(perf)
perf <- performance(pred, measure='prec')
plot(perf)
beer <- read.csv('http://www-958.ibm.com/software/analytics/manyeyes/datasets/af-er-beer-dataset/versions/1.txt', header=TRUE, sep='\t')
head(beer)
beer$good <- (beer$WR > 4.3)
beer$Ale <- grepl('Ale', beer$Type)
beer$IPA <- grepl('IPA', beer$Type)
beer$Stout <- grepl('Stout', beer$Type)
train.idx <- sample(1:nrow(beer), .7*nrow(beer))
training <- beer[train.idx,]
test <- beer[-train.idx,]
model <- glm(good ~ Ale + Stout + IPA , data=training, family='binomial')
head(beer)
model <- glm(good ~ Ale + Stout + IPA , data=training, family='binomial')
summary(model)
test.predict <- predict(model, test, type='response')
head(test.predict)
test.labels <- test.predict > 0.5
head(test.labels)
library('ROCR')
pred <- prediction(test.predict, test$good)
perf <- performance(pred, measure='acc')
plot(perf)
?performance
perf <- performance(pred, measure='ppv')
plot(perf)
summary(test.predict)
perf <- performance(pred, measure='rec')
?performance
perf <- performance(pred, measure='fscore')
perf <- performance(pred, measure='f')
plot(perf)
perf <- performance(pred, measure='auc')
perf
plot(auc)
plot(perf)
head(perf)
perf
perf <- performance(pred, measure='rec')
plot(perf)
perf <- performance(pred, measure='ppv')
plot(perf)
head(training)
install.packages('e1071')
?NaiveBayes
?naiveBayes
library('e1071')
?naiveBayes
model <- naiveBayes(good ~ Ale + Stout + IPA, data = train)
model <- naiveBayes(good ~ Ale + Stout + IPA, data = beer)
model <- naiveBayes(good ~ Ale + Stout + IPA, data = training)
testbeer <- predict(model, test)
testbeer <- predict(model, test, type = "raw")
my.path <- ('~/GeoTwit/visualizations/')
library(tm)
my.corpus <- Corpus(DirSource(my.path), readerControl= list (reader=readPlain))
my.corpus <- Corpus(DirSource(my.path), readerControl= list (reader=readPlain))
my_corpus.matrix <- TermDocumentMatrix(my.corpus)
View(my_corpus.matrix)
my_corpus.df <- as.data.frame(inspect(my_corpus.matrix))
View(my_corpus.df)
term.dist <- dist(my_corpus.df)
summary(term.dist)
hclust(term.dist)
plot(hclust(term.dist))
term_cluster <- hclust((term.dist), method="complete")
shorter_clust <- hclust(term_cluster, h=1)
shorter_clust <- cuttree(term_cluster, h=1)
shorter_clust <- cutree(term_cluster, h=1)
plot(hclust(shorter_clust))
term_cluster <- hclust((term.dist), method="complete")
shorter_clust <- cutree(term_cluster, h=1.4)
plot(hclust(shorter_clust))
term_cluster <- hclust((term.dist), method="complete")
plot(hclust(term_cluster))
term_cluster <- hclust(term.dist)
plot(hclust(term_cluster))
my_corpus.df <- as.data.frame(inspect(my_corpus.matrix))
term.dist <- dist(my_corpus.df)
term_cluster <- hclust(term.dist)
plot(hclust(term_cluster))
Size(my_corpus.df)
str(my_corpus.df)
hclust <- dist(my_corpus.df)
term.dist <- dist(my_corpus.df)
term_cluster <- hclust(term.dist)
plot(term_cluster)
dims(term.dist)
nrow(term.dist)
str(term.dist)
term.svd <- svd(term.dist)
dim(term.svd)
my_corpus.df <- transform(my_corpus.df, freq.dif=mid_atlantic_words_viz.txt-appalachia_words_viz.txt)
View(my_corpus.df)
mid_atlantic.df <- subset(my_corpus.df, freq.dif>0)
appalachia.df <- subset(my_corpus.df, freq.dif<0)
equal.df <- subset(my_corpus.df, freq.dif==0)
View(mid_atlantic.df)
View(equal.df)
optimal.spacing<-function(spaces) {
if(spaces>1) {
spacing<-1/spaces
if(spaces%%2 > 0) {
lim<-spacing*floor(spaces/2)
return(seq(-lim,lim,spacing))
}
else {
lim<-spacing*(spaces-1)
return(seq(-lim,lim,spacing*2))
}
}
else {
return(0)
}
}
mid_atlantic.spacing <- sapply(table(mid_atlantic.df$freq.dif), function(x) spacing(x))
mid_atlantic.spacing <- sapply(table(mid_atlantic.df$freq.dif), function(x) optimal.spacing(x))
appalachia.spacing <- sapply(table(appalachia.df$freq.dif), function(x) optimal.spacing(x))
equal.spacing<-sapply(table(equal.df$freq.dif), function(x) optimal.spacing(x))
mid_atlantic.optim <- rep(0, rnow(obama.df))
for (n in names(mid_atlantic.spacing)) {
mid_atlantic.optim[which(mid_atlantic.df$freq.dif==as.numeric(n))] <- mid_atlantic.spacing[[n]]
}
mid_atlantic.df <- transform(mid_atlantic.df, Spacing=mid_atlantic.optim)
mid_atlantic.optim <- rep(0, nrow(obama.df))
for (n in names(mid_atlantic.spacing)) {
mid_atlantic.optim[which(mid_atlantic.df$freq.dif==as.numeric(n))] <- mid_atlantic.spacing[[n]]
}
mid_atlantic.df <- transform(mid_atlantic.df, Spacing=mid_atlantic.optim)
mid_atlantic.optim <- rep(0, nrow(obama.df))
mid_atlantic.optim <- rep(0, nrow(mid_atlantic.df))
for (n in names(mid_atlantic.spacing)) {
mid_atlantic.optim[which(mid_atlantic.df$freq.dif==as.numeric(n))] <- mid_atlantic.spacing[[n]]
}
mid_atlantic.df <- transform(mid_atlantic.df, Spacing=mid_atlantic.optim)
appalachia.optim <- rep(0, nrow(appalachia.df))
for (n in names(appalachia.spacing)) {
appalachia.optim[which(appalachia.df$freq.dif==as.numeric(n))] <- appalachia.spacing[[n]]
}
appalachia.df <- transform(appalachia.df, Spacing=appalachia.optim)
equal.df$Spacing <- as.vector(equal.spacing)
mid_atlantic_vs_appalachia <-  ggplot(mid_atlantic.df, aes(x=freq.dif, y=Spacing))+geom_text(aes(size=mid_atlantic_words_viz.txt, label=row.names(mid_atlantic.df), colour=freq.dif))+
geom_text(data=appalachia.df, aes(x=freq.dif, y=Spacing, label=row.names(appalachia.df), size=appalachia_words_viz.txt, color=freq.dif))+
geom_text(data=equal.df, aes(x=freq.dif, y=Spacing, label=row.names(equal.df), size=mid_atlantic_words_viz.txt, color=freq.dif))+
scale_size(range=c(3,11), name="Word Frequency")+scale_colour_gradient(low="darkred", high="darkblue", guide="none")+
scale_x_continuous(breaks=c(min(appalachia.df$freq.dif),0,max(mid_atlantic.df$freq.dif)),labels=c("Said More in Appalachia","Said Equally","Said More in Mid Atlantic"))+
scale_y_continuous(breaks=c(0),labels=c(""))+xlab("")+ylab("")+theme_bw()+
theme(panel.grid.major=element_blank(),panel.grid.minor=element_blank(), title=element_text("Word Cloud 2.0, Twitter Talk (Mid Atlantic vs. Appalachia)"))
ggsave(plot=tucson.cloud,filename="ma_app.png",width=13,height=7)
library(ggplot2)
mid_atlantic_vs_appalachia <-  ggplot(mid_atlantic.df, aes(x=freq.dif, y=Spacing))+geom_text(aes(size=mid_atlantic_words_viz.txt, label=row.names(mid_atlantic.df), colour=freq.dif))+
geom_text(data=appalachia.df, aes(x=freq.dif, y=Spacing, label=row.names(appalachia.df), size=appalachia_words_viz.txt, color=freq.dif))+
geom_text(data=equal.df, aes(x=freq.dif, y=Spacing, label=row.names(equal.df), size=mid_atlantic_words_viz.txt, color=freq.dif))+
scale_size(range=c(3,11), name="Word Frequency")+scale_colour_gradient(low="darkred", high="darkblue", guide="none")+
scale_x_continuous(breaks=c(min(appalachia.df$freq.dif),0,max(mid_atlantic.df$freq.dif)),labels=c("Said More in Appalachia","Said Equally","Said More in Mid Atlantic"))+
scale_y_continuous(breaks=c(0),labels=c(""))+xlab("")+ylab("")+theme_bw()+
theme(panel.grid.major=element_blank(),panel.grid.minor=element_blank(), title=element_text("Word Cloud 2.0, Twitter Talk (Mid Atlantic vs. Appalachia)"))
ggsave(plot=mid_atlantic_vs_appalachia,filename="ma_app.png",width=13,height=7)
mid_atlantic_vs_appalachia
mid_atlantic_vs_appalachia <-  ggplot(mid_atlantic.df, aes(x=freq.dif, y=Spacing))+geom_text(aes(size=mid_atlantic_words_viz.txt, label=row.names(mid_atlantic.df), colour=freq.dif))+
geom_text(data=appalachia.df, aes(x=freq.dif, y=Spacing, label=row.names(appalachia.df), size=appalachia_words_viz.txt, color=freq.dif))+
geom_text(data=equal.df, aes(x=freq.dif, y=Spacing, label=row.names(equal.df), size=mid_atlantic_words_viz.txt, color=freq.dif))+
scale_size(range=c(3,11), name="Word Frequency")+scale_colour_gradient(low="darkred", high="darkblue", guide="none")+
scale_x_continuous(breaks=c(min(appalachia.df$freq.dif),0,max(mid_atlantic.df$freq.dif)),labels=c("Said More in Appalachia","Said Equally","Said More in Mid Atlantic"))+
scale_y_continuous(breaks=c(0),labels=c(""))+xlab("")+ylab("")+theme_bw(base_family= 'Helvetica')+
theme(panel.grid.major=element_blank(),panel.grid.minor=element_blank(), title=element_text("Word Cloud 2.0, Twitter Talk (Mid Atlantic vs. Appalachia)"))
ggsave(plot=mid_atlantic_vs_appalachia,filename="ma_app.png",width=13,height=7)
remove.packages('ggplot2')
install.packages('ggplot2')
setwd("~/GeoTwit")
train_data <- read.csv('short_clean_train.csv')
ne_words <- read.csv('ne_wordcount.csv')
train_words <- cbind(train_data, ne_words)
ne_words <- read.csv('ne_wordcount.csv')
app_words <- read.csv('appalachia_wordcount.csv')
train_words <- cbind(train_data, ne_words, app_words)
train_words <- cbind(train_data, ne_words)
View(app_words)
ne_words <- ne_words[-899,]
View(ne_words)
ne_words <- read.csv('ne_wordcount.csv')
View(train_words)
train_words[1] <- NULL
train_words[1] <- NULL
View(train_words)
train_words$Is_New_England <- grepl('New England', train$Region)
train_words$Is_New_England <- grepl('New England', train_words$Region)
train_words$Is_Appalachia <- grepl('Appalachia', train_words$Region)
set.seed(43)
train_words$fold <- sample(1:10, nrow(train_words), replace=TRUE)
train <- subset(train_words, fold != 3)
test <- subset(train_words, fold == 3)
model_glm <- glm(Is_New_England ~ New.England.Words, data = train, family='binomial')
test.predict <- predict(model_nb, test, type="response")
test.predict <- predict(model_glm, test, type="response")
library('ROCR')
pred <- prediction(test.predict, test$Is_New_England)
perf <- performance(pred, measure='acc')
plot(perf)
perf_actual <- performance(pred, measure='recall')
perf_auc <- performance(pred, measure='auc')
perf_auc
perf
test <- read.csv('short_test.csv')
ne_words_test <- read.csv('ne_wordcount_test.csv')
test_words <- cbind(test, ne_words_test)
ne_words_test <- read.csv('ne_wordcount_test.csv')
test_words <- cbind(test, ne_words_test)
test_words$Is_New_England <- grepl('New England', test_words$Region)
model_glm_final <- glm(Is_New_England ~ New.England.Words, data = train_words)
predictions <- predict(model_final_nb, test_words, type="response")
predictions <- predict(model__glm_final, test_words, type="response")
predictions <- predict(model_glm_final, test_words, type="response")
summary(predictions)
