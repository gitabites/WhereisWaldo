train.index <- sample(1:N,  train.pct* N)  #randomly sample indices for your training set
train.data <- data[train.index, ] #separate out those indices to your traing set
test.data <- data[-train.index, ] #everything else goes to your test set
#TRAIN YOUR MODEL (k = 3, but you could set it as anything)
test.predict <- knn( train = train.data[,c(1,2,3,4)] , test = test.data[,c(1,2,3,4)], cl = train.data$Species, k = 3)
#PRINT CONFUSION MATRIX
print(table(test.data$Species, test.labels))
#OUTPUT ACCURACY
sum ( test.data$Species != test.labels ) / nrow(test.data)
setwd('Users/clairewillett/538model')
getwd
setwd('User/clairewillett/538model')
setwd('Users/clairewillett/538model')
getwd()
setwd("Users/clairewillett/538model")
batting <- read.csv('Batting.csv')
getwd
getwd()
getwd()
read.csv("/Users/clairewillett/train.csv")
read.csv("/Users/clairewillett/train.csv")
first_try -> read.csv("/Users/clairewillett/train.csv")
View(first_try)
first_try
first_try -> read.csv("/Users/clairewillett/train.csv")
first_try <) read.csv("/Users/clairewillett/train.csv")
first_try <- read.csv("/Users/clairewillett/train.csv")
View(first_try)
?ddply
?split
split_first_try <- function(first_try, seed=NULL) {
if (!is.null(seed)) set.seed(seed)
index <- 1:nrow(first_try)
}
split_first_try <- function(first_try, seed=NULL) {
if (!is.null(seed)) set.seed(seed)
index <- 1:nrow(first_try)
trainindex <- sample(index, trunc(length(index)/2))
trainset <- first_try[trainindex, ]
testset <- first_try[-trainindex, ]
list(trainset=trainset, testset=testset)
}
View(trainset)
splitdf <- function(dataframe, seed=NULL) {
if (!is.null(seed)) set.seed(seed)
index <- 1:nrow(dataframe)
trainindex <- sample(index, trunc(length(index)/2))
trainset <- dataframe[trainindex, ]
testset <- dataframe[-trainindex, ]
list(trainset=trainset,testset=testset)
}
splits <- splitdf(first_try, seed=5000)
str(splits)
lapply(splits,nrow)
lapply(splits,head)
#now data is split into two sets, one training and one test
#now it's time to build the model
model <- lm(SalaryNormalized ~ Company, Title, data=trainset)
View(trainset)
training <-splits$strainset
testing <- splits$testset
#ok sorry, now the data is split into two sets and now it's time to build model
model <- lm(SalaryNormalized ~ Company, Title, data=training)
training <- splits$trainset
model <- lm(SalaryNormalized ~ Company, Title, data=training)
summary(model)
mae <- function(x,y)
{
sum( abs(x-y)) /length(x)
}
#now have the other evalation function (besides rsquared)
#now it's prediction time
test.predict <- predict(model, test)
test.predict <- predict(model, testing)
load("~/.RData")
train_sal <- read.csv("train.csv")
nrow(train_sal)
head(train_sal)
split_sal <- function(train_sal, seed=NULL) {}
split_sal <- function(train_sal, seed=NULL) {
if (!is.null(seed)) set.seed(seed)
index <- 1:nrow(train_sal)
trainindex <- sample(index, trunc(length(index/2)))
trainset <- train_sal[trainindex, ]
testset <- train_sal[-trainindex, ]
list(trainset=trainset, testset=testset)
}
split_data <- <- function(dataframe, seed=NULL) {
if (!is.null(seed)) set.seed(seed)
index <- 1:nrow(dataframe)
trainindex <- sample(index, trunc(length(index)/2))
trainset <- dataframe[trainindex, ]
testset <- dataframe[-trainindex, ]
list(trainset=trainset,testset=testset)
}
split_data <- function(dataframe, seed=NULL) {
if (!is.null(seed)) set.seed(seed)
index <- 1:nrow(dataframe)
trainindex <- sample(index, trunc(length(index)/2))
trainset <- dataframe[trainindex, ]
testset <- dataframe[-trainindex, ]
list(trainset=trainset,testset=testset)
}
split_it <- split_data(train_sal, seed=5000)
?str
str(split_it)
?lapply
lapply(split_it,nrow)
lapply(split_it,head)
trainsal <- split_it$trainset
testsal <- split_it$testset
trainsal(head)
View(trainsal)
head(trainsal)
model <- lm(SalaryNormalized ~ Category, LocationNormalized, data=trainsal)
model1 <- model
model2 <- lm(SalaryNormalized ~ Category, LocationNormalized, Title, data=trainsal)
model2 <- lm(SalaryNormalized ~ Category, LocationNormalized, Title, data=trainsal, weights=NULL)
model2 <- lm(SalaryNormalized ~ Category, LocationNormalized, Title, data=trainsal)
model2 <- lm(SalaryNormalized ~ Category, LocationNormalized, Company, data=trainsal)
model2 <- lm(SalaryNormalized ~ Category, LocationNormalized, ContractTime, data=trainsal)
model1 <- lm(SalaryNormalized ~ Category + LocationNormalized, data=trainsal)
model2 <- lm(SalaryNormalized ~ Category + LocationNormalized + Title, data=trainsal)
mae <- function(x,y)
{
sum( abs(x-y) ) /length(x)
{
mae <- function(x,y)
{
sum( abs(x-y) ) /length(x)
{
]
mae <- function(x,y) {
sum( abs(x-y)) /length(X)
}
test.model1 <- predict(model1, test)
test.model1 <- predict(model1, testsal)
test.model2 <- predict(model2, testsal)
mae(test.model1, testsal$NormalizedSalary)
model3 <- lm(SalaryNormalized ~ Category + Title, data=trainsal)
test.model3 <- predict(model3, testsal)
mae(test.model3, testsal$NormalizedSalary)
mae <- function(x,y)
{
sum( abs(x-y) ) /length(x)
{
]
LocationNormalized.counts
aggregate(trainsal$SalaryNormalized, by = trainsal[c('LocationNormalized')], length)
trainsal <- read.csv('train.csv')
aggregate(trainsal$SalaryNormalized, by = trainsal[c('LocationNormalized')], length)
location <- aggregate(trainsal$SalaryNormalized, by = trainsal[c('LocationNormalized')], length)
location[order(x)]
sort(location)
location(order(LocationNormalized))
location[order(LocationNormalized)]
location[order(LocationNormalized),]
location[order(location$LocationNormalized),]
location[order(location$x),]
location_ordered <- location[order(location$x),]
View(location_ordered)
head(location_ordered, 610L)
head(location_ordered, -610L)
tail(location_ordered, -610L)
trainsal <- read.csv('train.csv')
location <- aggregate(trainsal, by = trainsal[c('LocationNormalized')], length)
View(location)
trainsal <- read.csv('train.csv')
location <- aggregate(trainsal$SalaryNormalized, by = trainsal[c('LocationNormalized')], length)
location_ordered <- location[order(location$x),]
location_order <- tail(location_ordered, -610L)
View(location_order)
trainsal_full <- read.csv('train.csv')
View(trainsal_full)
trainsal_exp <- merge(location_order, trainsal_full)
View(trainsal_exp)
category <- aggregate(trainsal_exp$SalaryNormalized, by =trainsal_exp[c('Category')], length)
View(category)
grepl("Senior|Snr", trainsal_exp$words)
trainsal_exp[, "Management Title"] <- grepl("Senior|Snr", trainsal_exp$words)
View(trainsal_exp)
trainsal_exp[, "Management Title"] <- grepl("Senior|Snr", trainsal_exp$Title)
View(trainsal_exp)
trainsal_exp[, "Management Title"] <- grepl("Senior|Snr|Manager|Supervisor|Deputy", trainsal_exp$Title)
View(trainsal_exp)
trainsal <- trainsal_exp
split_data <- function(dataframe, seed=NULL) {
if (!is.null(seed)) set.seed(seed)
index <- 1:nrow(dataframe)
trainindex <- sample(index, trunc(length(index)/2))
trainset <- dataframe[trainindex, ]
testset <- dataframe[-trainindex, ]
list(trainset=trainset,testset=testset)
}
split_it <- split_data(trainsal, seed=5000)
lapply(split_it,grow)
lapply(split_it,nrow)
trainsal <- split_it$trainset
testsal <- split_it$testset
view(trainsal)
View(trainsal)
head(trainsal)
model1 <- lm(SalaryNormalized ~ Category + LocationNormalized, data=trainsal)
names(trainsal)[14]<-"MgmtTitle"
model2 <- lm(SalaryNormalized ~ Category + LocationNormalized + MgmtTitle, data=trainsal)
model3 <- lm(SalaryNormalized ~ Category + MgmtTitle, data=trainsal)
mae <- function(x,y)
{
sum( abs(x-y) ) /length(x)
}
test.model1 <- predict(model1, testsal)
testsal[!testsal$LocationNormalized == "Bicester|Pontefract|Sevenoaks", ]
test.model1 <- predict(model1, testsal)
View(testsal)
testsal1 <- testsal[!testsal$LocationNormalized == "Bicester|Pontefract|Sevenoaks", ]
test.model1 <- predict(model1, testsal1)
testsal1 <- testsal[testsal$LocationNormalized != "Bicester|Pontefract|Sevenoaks", ]
test.model1 <- predict(model1, testsal1)
testsal1 <- testsal[testsal$LocationNormalized != "Bicester", ]
test.model1 <- predict(model1, testsal1)
testsal1 <- testsal[testsal$LocationNormalized != ("Bicester", "Pontefract", "Sevenoaks") ,  ]
testsal1 <- testsal[(testsal$LocationNormalized != "Pontefract") & (testsal$LocationNormalized != "Sevenoaks") ,  ]
test.model1 <- predict(model1, testsal1)
testsal1 <- testsal[(testsal$LocationNormalized != "Pontefract") & (testsal$LocationNormalized != "Sevenoaks") & (testsal$LocationNormalized != "Bicester") ,  ]
test.model1 <- predict(model1, testsal1)
test.model2 <- predict(model2, testsal1)
testsal[, "MgmtTitle"] <- grepl("Senior|Snr|Manager|Supervisor|Deputy", testsal$Title)
testsal1[, "MgmtTitle"] <- grepl("Senior|Snr|Manager|Supervisor|Deputy", testsal1$Title)
test.model2 <- predict(model2, testsal1)
test.model3 <- predict(model3, testsal1)
mae(test.model1, testsal1$NormalizedSalary)
mae(test.model2, testsal1$NormalizedSalary)
summary(model1)
summary(model2)
summary(model3)
mae <- function(x,y)
{
mean ( abs(x-y) )
}
mae(test.model1, testsal1$NormalizedSalary)
View(testsal1)
model1 <- lm(SalaryNormalized ~ Category + LocationNormalized, data=trainsal)
test.model1 <- predict(model1, testsal1)
mae(test.model1, testsal1$NormalizedSalary)
trainsal <- read.csv('train.csv')
location <- aggregate(trainsal$SalaryNormalized, by = trainsal[c('LocationNormalized')], length)
location_ordered <- location[order(location$x),]
tail(location_ordered, -610L)
location_ordered <- tail(location_ordered, -610L)
trainsal_full <- read.csv('train.csv')
trainsal <- merge(location_order, trainsal_full)
View(trainsal)
trainsal[, "MagmtTitle"] <- grepl("Senior|Snr|Manager|Supervisor|Deputy", trainsal$Title)
View(trainsal)
model.trainsal <- trainsal [,c("LocationNormalized", "ID", "Title", "ContractType", "ContractTime", "Category", "SalaryNormalized", "MgmtTitle")]
model.trainsal <- trainsal [, c("LocationNormalized", "Id", "Title", "ContractType", "ContractTime", "Category", "SalaryNormalized", "MgmtTitle")]
model.trainsal <- trainsal[, c("LocationNormalized", "Id", "Title", "ContractType", "ContractTime", "Category", "SalaryNormalized", "MgmtTitle")]
model.trainsal <- trainsal[c("LocationNormalized", "Id", "Title", "ContractType", "ContractTime", "Category", "SalaryNormalized", "MgmtTitle"),]
View(model.trainsal)
model.trainsal <- trainsal[, c("LocationNormalized", "Id", "Title", "ContractType", "ContractTime", "Category", "SalaryNormalized", "MgmtTitle"),]
model.trainsal <- trainsal[, c("LocationNormalized", "Id", "Title", "ContractType", "ContractTime", "Category", "SalaryNormalized", "MgmtTitle")]
model.trainsal <- trainsal[c-(-2, -5, -6, -9, -11, -13)]
model.trainsal <- trainsal[, c-(-2, -5, -6, -9, -11, -13)]
model.trainsal <- trainsal[, c("LocationNormalized", "Id", "Title", "ContractType", "ContractTime", "Category", "SalaryNormalized", "MgmtTitle")]
model.trainsal <- trainsal[c("-2", "-5", "-6", "-9", "-11", "-13")]
model.trainsal <- trainsal[c(-2, -5, -6, -9, -11, -13)]
View(model.trainsal)
split_data <- function(dataframe, seed=NULL) {
if (!is.null(seed)) set.seed(seed)
index <- 1:nrow(dataframe)
trainindex <- sample(index, trunc(length(index)/2))
trainset <- dataframe[trainindex, ]
testset <- dataframe[-trainindex, ]
list(trainset=trainset,testset=testset)
}
split_it <- split_data(trainsal, seed=5000)
trainsal <- split_it$trainset
testsal <- split_it$testset
View(trainsal)
split_it <- split_data(model.trainsal, seed=5000)
trainsal <-spli_it$trainset
trainsal <-split_it$trainset
testsal <- split_it$testset
View(trainsal)
View(testsal)
model1 <- lm(SalaryNormalized ~ LocationNormalized, data=trainsal)
model1 <- lm(SalaryNormalized ~ LocationNormalized + Category, data=trainsal)
model1 <- lm(SalaryNormalized ~ LocationNormalized, data=trainsal)
model2 <- lm(SalaryNormalized ~ LocationNormalized + Category, data=trainsal)
model3 <- lm(SalaryNormalized ~ Category + ContractType, data=trainsal)
model3 <- lm(SalaryNormalized ~ Category + ContractType + ContractTime, data=trainsal)
model3 <- lm(SalaryNormalized ~ Category + ContractType, data=trainsal)
model4 <- lm(SalaryNormalized ~ Category + ContractType + ContractTime, data=trainsal)
model5 <- lm(SalaryNormalized ~ Category + MgmtTitle, data=trainsal)
model5 <- lm(SalaryNormalized ~ Category + MagmtTitle, data=trainsal)
test.model1 <- predict(model1, testsal)
testsal1 <- testsal[(testsal$LocationNormalized != "Pontefract") & (testsal$LocationNormalized != "Sevenoaks") & (testsal$LocationNormalized != "Bicester") ,  ]
test.model1 <- predict(model1, testsal1)
test.model2 <- predict(model2, testsal1)
test.model3 <- predict(model3, testsal1)
test.model4 <- predict(model4, testsal1)
test.model5 <- predict(model5, testsal1)
mae <- function(x,y)
{
mean( abs(x-y) ) /length(x)
}
mae(test.model1, testsal1$SalaryNormalized)
mae(test.model2, testsal1$SalaryNormalized)
mae(test.model3, testsal1$SalaryNormalized)
mae(test.model4, testsal1$SalaryNormalized)
mae(test.model5, testsal1$SalaryNormalized)
summary(model1)
summary(model2)
summary(model3)
summary(model4)
summary(model5)
model6 <- lm(SalaryNormalized ~ LocationNormalized + Category + MagmtTitle + ContractType + ContractTime, data=trainsal)
model7 <- lm(SalaryNormalized ~ LocationNormalized + Category + ContractType + ContractTime, data=trainsal)
model8 <- lm(SalaryNormalized ~ Category + ContractType + ContractTime + MagmtTitle, data=trainsal)
model9 <- lm(SalaryNormalized ~ LocationNormalized + Category + MagmtTitle, data=trainsal)
test.model6 <- predict(model6, testsal)
test.model6 <- predict(model6, testsal1)
test.model7 <- predict(model7, testsal1)
test.model8 <- predict(model8, testsal1)
test.model10 <- predict(model9, testsal1)
mae(test.model6, testsal1$SalaryNormalized)
mae(test.model7, testsal1$SalaryNormalized)
mae(test.model8, testsal1$SalaryNormalized)
mae(test.model9, testsal1$SalaryNormalized)
mae(test.model10, testsal1$SalaryNormalized)
summary(model6)
summary(model7)
summary(model8)
summary(model9)
model10 <- lm(SalaryNormalized ~ LocationNormalized + Category + MagmtTitle + ContractType, data=trainsal)
test.model10 <- predict(model10, testsal1)
mae(test.model10, testsal1$SalaryNormalized)
model10 <- lm(SalaryNormalized ~ LocationNormalized + Category + MagmtTitle + ContractTime, data=trainsal)
test.model10 <- predict(model10, testsal1)
mae(test.model10, testsal1$SalaryNormalized)
model10 <- lm(SalaryNormalized ~ LocationNormalized + MagmtTitle, data=trainsal)
mae(test.model10, testsal1$SalaryNormalized)
test.model10 <- predict(model10, testsal1)
mae(test.model10, testsal1$SalaryNormalized)
install.packages('DAAG')
library('DAAG')
cv.lm(df=testsal, form.lm=formula(SalaryNormalized ~ LocationNormalized + Category + MagmtTitle + ContractType + ContractTime), m=2)
cv.lm(df=testsal1, form.lm=formula(SalaryNormalized ~ LocationNormalized + Category + MagmtTitle + ContractType + ContractTime), m=2)
q()
mae <- function(one, other) {
return(mean(abs(one - other)))
}
mae(5, 2)
alltrain <- read.csv("train.csv")
alltrain <- read.csv("train-1.csv")
set.seed(42)
alltrain$fold <- sample(1:10, nrow(alltrain), replace = TRUE)
train <- subset(alltrain, fold != 3)
test <- subset(alltrain, fold == 3)
#what is the dumbest model we could do? Let'spredict every salary is
mae(0, train$SalaryNormalized)
mae(0, test$SalaryNormalized)
hist(train$SalaryNormalized)
model <- lm(SalaryNormalized ~ 1, data=training)
#second dumbest model is to predict every salary is the mean, which is what the 1 above stands for
mae(fitted(model), train$SalaryNormalized)
mae(predict(model,test), test$SalaryNormalized)
error_from_fold <- function(n) {
model <- lm(Salary$Normalized -1, data=subset(alltrain, fold != n))
test <- subset(alltrain, fold == n)
error <- mae(predict(model,test), test$SalaryNormalized)
return(error)
}
error_from_fold(3)
error_from_fold <- function(n) {
model <- lm(SalaryNormalized ~ 1, data=subset(alltrain, fold != n))
test <- subset(alltrain, fold == n)
error <- mae(predict(model,test), test$SalaryNormalized)
return(error)
}
error_from_fold(3)
sapply(1:10, error_from_fold)
#to work with actual test data
model <- lm(SalaryNormalized ~ ContractType, data=train)
library(glmnet)
model <- cv.glmnet(model.matrix(train$ContractType), matrix(train$SalaryNormalized))
model <- cv.glmnet(~model.matrix(train$ContractType), matrix(train$SalaryNormalized))
model <- cv.glmnet(model.matrix(~train$ContractType), matrix(train$SalaryNormalized))
as.vector(predict(model, model.matrix(~test$ContractType), s="lambda.min"))
mae(as.vector(predict(model, model.matrix(~test$ContractType), s="lambda.min")), test$SalaryNormalized)
hist(train$SalaryNormalized)
hist(log(train$SalaryNormalized))
model <- lm(log(SalaryNormalized ~ ContractType, data=train))
install.packages("knitr")
library(knitr)
data(iris)
iris$sep <- factor(ifelse(iris$Sepal.Length > 6, "big", "small"))
iris$pet <- factor(ifelse(iris$Petal.Length > 4, "long", "short"))
(counts <- with(iris, table(sep, pet)))
model <- glm(pet ~ sep, data=iris, family=binomial)
coef(model)
(logodds < predict(model)[49:52])
logodds < predict(model)[49:52]
(logodds <- predict(model)[49:52])
(probs <- predict(model, type="response")[49:52])
exp(logodds)/(1+ exp(logodds))
prob.talbe(counts,1)
prob.table(counts,1)
prop.table(counts,1)
exp(logodds)
probs / (1- probs)
coef(model)
library('ROCR')
pred <- prediction(test.predict, test$good)
beer <- read.csv('http://www-958.ibm.com/software/analytics/manyeyes/datasets/af-er-beer-dataset/versions/1.txt', header=TRUE, sep='\t')
head(beer)
beer$good <- (beer$WR > 4.3)
beer$Ale <- grepl('Ale', beer$Type)
beer$IPA <- grepl('IPA', beer$Type)
beer$Stout <- grepl('Stout', beer$Type)
train.idx <- sample(1:nrow(beer), .7*nrow(beer))
training <- beer[train.idx,]
test <- beer[-train.idx,]
model <- glm(good ~ Ale + Stout + IPA , data=training, family='binomial')
test.predict <- predict(model, test, type="response")
library('ROCR')
pred <- prediction(test.predict, test$good)
plot(pred)
beer <- read.csv('http://www-958.ibm.com/software/analytics/manyeyes/datasets/af-er-beer-dataset/versions/1.txt', header=TRUE, sep='\t')
head(beer)
beer$good <- (beer$WR > 4.3)
beer$Ale <- grepl('Ale', beer$Type)
beer$IPA <- grepl('IPA', beer$Type)
beer$Stout <- grepl('Stout', beer$Type)
train.idx <- sample(1:nrow(beer), .7*nrow(beer))
training <- beer[train.idx,]
test <- beer[-train.idx,]
model <- glm(good ~ Ale + Stout + IPA , data=training, family='binomial')
test.predict <- predict(model, test, type="response")
library('ROCR')
pred <- prediction(test.predict, test$good)
perf <- performance(pred, measure='acc')
plot(pef)
plot(perf)
perf <- performance(pred, measure='prec')
plot(perf)
beer <- read.csv('http://www-958.ibm.com/software/analytics/manyeyes/datasets/af-er-beer-dataset/versions/1.txt', header=TRUE, sep='\t')
head(beer)
beer$good <- (beer$WR > 4.3)
beer$Ale <- grepl('Ale', beer$Type)
beer$IPA <- grepl('IPA', beer$Type)
beer$Stout <- grepl('Stout', beer$Type)
train.idx <- sample(1:nrow(beer), .7*nrow(beer))
training <- beer[train.idx,]
test <- beer[-train.idx,]
model <- glm(good ~ Ale + Stout + IPA , data=training, family='binomial')
head(beer)
model <- glm(good ~ Ale + Stout + IPA , data=training, family='binomial')
summary(model)
test.predict <- predict(model, test, type='response')
head(test.predict)
test.labels <- test.predict > 0.5
head(test.labels)
library('ROCR')
pred <- prediction(test.predict, test$good)
perf <- performance(pred, measure='acc')
plot(perf)
?performance
perf <- performance(pred, measure='ppv')
plot(perf)
summary(test.predict)
perf <- performance(pred, measure='rec')
?performance
perf <- performance(pred, measure='fscore')
perf <- performance(pred, measure='f')
plot(perf)
perf <- performance(pred, measure='auc')
perf
plot(auc)
plot(perf)
head(perf)
perf
perf <- performance(pred, measure='rec')
plot(perf)
perf <- performance(pred, measure='ppv')
plot(perf)
head(training)
install.packages('e1071')
?NaiveBayes
?naiveBayes
library('e1071')
?naiveBayes
model <- naiveBayes(good ~ Ale + Stout + IPA, data = train)
model <- naiveBayes(good ~ Ale + Stout + IPA, data = beer)
model <- naiveBayes(good ~ Ale + Stout + IPA, data = training)
testbeer <- predict(model, test)
testbeer <- predict(model, test, type = "raw")
setwd("~/GeoTwit/visualizations")
install.packages('tm')
comp_words <- Corpus(DirSource("/GeoTwit/visualizations/"))
load(tm)
library(tm)
comp_words <- Corpus(DirSource("/GeoTwit/visualizations/"))
comp_words <- Corpus(DirSource("/GeoTwit/visualizations"))
comp_words <- Corpus(DirSource("/visualizations"))
comp_words <- Corpus(DirSource("/visualizations", readerControl = list(language="lat"))))
comp_words <- Corpus(DirSource("/visualizations", readerControl = list(language="lat")))
comp_words <- Corpus(DirSource("/visualizations", readerControl = list(language="lat")))
comp_words <- system.file("appalachia_words_viz", "mid_atlantic_words_viz", "visualizations", package="tm")
comp_words <- Corpus(DirSource(comp_words, encoding="UTF-8", readerControl= list(language="english")))
comp_words <- Corpus(DirSource(comp_words))
words_again <- Corpus(DirSource(comp_words, encoding="UTF-8", readerControl= list(language="english")))
